{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c59528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this project I will create a Deep learning regression model that is capable \n",
    "# of predicting the percent chance of admission for students applying to graduate school\n",
    "\n",
    "# admissions_data.csv provided by codecademy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a1a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e75f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "0           1        337          118                  4  4.5   4.5  9.65   \n",
      "1           2        324          107                  4  4.0   4.5  8.87   \n",
      "2           3        316          104                  3  3.0   3.5  8.00   \n",
      "3           4        322          110                  3  3.5   2.5  8.67   \n",
      "4           5        314          103                  2  2.0   3.0  8.21   \n",
      "\n",
      "   Research  Chance of Admit   \n",
      "0         1              0.92  \n",
      "1         1              0.76  \n",
      "2         1              0.72  \n",
      "3         1              0.80  \n",
      "4         0              0.65  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('admissions_data.csv')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee00cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
      "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ac35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:, 0:-1]\n",
    "labels = data['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062e92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccf1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_train_scale = scaler.fit_transform(X_train)\n",
    "features_test_scale = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575abe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "my_model = Sequential()\n",
    "\n",
    "input = InputLayer(input_shape = features_train_scale.shape[1])\n",
    "\n",
    "my_model.add(input)\n",
    "my_model.add(Dense(64,activation = 'relu'))\n",
    "my_model.add(Dense(8,activation = 'relu'))\n",
    "my_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b385c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                576       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,105\n",
      "Trainable params: 1,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Sequential.summary(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da243cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(learning_rate=0.01, name='Adam')\n",
    "my_model.compile(optimizer = opt, loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3243a79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "400/400 [==============================] - 3s 3ms/step - loss: 0.0567 - mae: 0.1576\n",
      "Epoch 2/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0069 - mae: 0.0645\n",
      "Epoch 3/40\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0046 - mae: 0.0527\n",
      "Epoch 4/40\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0044 - mae: 0.0514\n",
      "Epoch 5/40\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0041 - mae: 0.0491\n",
      "Epoch 6/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0467\n",
      "Epoch 7/40\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.0043 - mae: 0.0496\n",
      "Epoch 8/40\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.0050 - mae: 0.0566\n",
      "Epoch 9/40\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.0050 - mae: 0.0551\n",
      "Epoch 10/40\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.0045 - mae: 0.0512\n",
      "Epoch 11/40\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.0051 - mae: 0.0557\n",
      "Epoch 12/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0536\n",
      "Epoch 13/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0509\n",
      "Epoch 14/40\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0049 - mae: 0.0539\n",
      "Epoch 15/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0560\n",
      "Epoch 16/40\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.0044 - mae: 0.0510\n",
      "Epoch 17/40\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0050 - mae: 0.0540\n",
      "Epoch 18/40\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0052 - mae: 0.0549\n",
      "Epoch 19/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0558\n",
      "Epoch 20/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0496\n",
      "Epoch 21/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0504\n",
      "Epoch 22/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0506\n",
      "Epoch 23/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0488\n",
      "Epoch 24/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0453\n",
      "Epoch 25/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0490\n",
      "Epoch 26/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0485\n",
      "Epoch 27/40\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0499\n",
      "Epoch 28/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0492\n",
      "Epoch 29/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0486\n",
      "Epoch 30/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0463\n",
      "Epoch 31/40\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0042 - mae: 0.0502\n",
      "Epoch 32/40\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0038 - mae: 0.0476\n",
      "Epoch 33/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0475\n",
      "Epoch 34/40\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0039 - mae: 0.0480\n",
      "Epoch 35/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0495\n",
      "Epoch 36/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0474\n",
      "Epoch 37/40\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0477\n",
      "Epoch 38/40\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.0046 - mae: 0.0529\n",
      "Epoch 39/40\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.0037 - mae: 0.0463\n",
      "Epoch 40/40\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.0038 - mae: 0.0479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5ffde85e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(features_train_scale, y_train, epochs = 40, batch_size =1,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9989f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mse, res_mae = my_model.evaluate(features_test_scale,y_test,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9905fbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08298896126705316 0.0677882507443428\n"
     ]
    }
   ],
   "source": [
    "print(res_mse**.5, res_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa5e0f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    my_model = Sequential()\n",
    "    input = InputLayer(input_shape = features_train_scale.shape[1])\n",
    "    my_model.add(input)\n",
    "    my_model.add(Dense(64,activation = 'relu'))\n",
    "    my_model.add(Dense(8,activation = 'relu'))\n",
    "    my_model.add(Dense(1))\n",
    "    opt = Adam(learning_rate=0.01, name='Adam')\n",
    "    my_model.compile(optimizer = opt, loss=\"mse\", metrics=[\"mae\"])\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81e1ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04706c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search automated tuning for batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9080b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_randomized_search():\n",
    "  param_grid = {'batch_size': sp_randint(1, 16), 'epochs': sp_randint(10, 100)}\n",
    "  model = KerasRegressor(model=func, verbose=0)\n",
    "  grid = RandomizedSearchCV(estimator = model, param_distributions=param_grid, scoring = make_scorer(mean_squared_error, greater_is_better=False), n_iter = 12)\n",
    "  grid_result = grid.fit(features_train_scale, y_train, verbose = 0)\n",
    "  print(grid_result)\n",
    "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "  means = grid_result.cv_results_['mean_test_score']\n",
    "  stds = grid_result.cv_results_['std_test_score']\n",
    "  params = grid_result.cv_results_['params']\n",
    "  for mean, stdev, param in zip(means, stds, params):\n",
    "      print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd245a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(estimator=KerasRegressor(model=<function func at 0x000001E5881D3EE0>, verbose=0),\n",
      "                   n_iter=12,\n",
      "                   param_distributions={'batch_size': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E597944190>,\n",
      "                                        'epochs': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E5894231F0>},\n",
      "                   scoring=make_scorer(mean_squared_error, greater_is_better=False))\n",
      "Best: -0.004002 using {'batch_size': 11, 'epochs': 72}\n",
      "-0.004701 (0.000862) with: {'batch_size': 10, 'epochs': 97}\n",
      "-0.004933 (0.001133) with: {'batch_size': 7, 'epochs': 12}\n",
      "-0.005080 (0.000288) with: {'batch_size': 3, 'epochs': 93}\n",
      "-0.004872 (0.000627) with: {'batch_size': 5, 'epochs': 89}\n",
      "-0.004613 (0.000966) with: {'batch_size': 2, 'epochs': 35}\n",
      "-0.004097 (0.000618) with: {'batch_size': 2, 'epochs': 20}\n",
      "-0.005562 (0.000600) with: {'batch_size': 11, 'epochs': 19}\n",
      "-0.005033 (0.000658) with: {'batch_size': 1, 'epochs': 25}\n",
      "-0.004742 (0.000882) with: {'batch_size': 11, 'epochs': 69}\n",
      "-0.004002 (0.000637) with: {'batch_size': 11, 'epochs': 72}\n",
      "-0.004486 (0.000718) with: {'batch_size': 5, 'epochs': 94}\n",
      "-0.004604 (0.000742) with: {'batch_size': 10, 'epochs': 97}\n"
     ]
    }
   ],
   "source": [
    "do_randomized_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a grid search to tune batch size and epochs using knowledge from the random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5de9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_grid_search():    \n",
    "  batch_size = [10, 15,20,]\n",
    "  epochs = [10, 30,35]\n",
    "  model = KerasRegressor(model=func, verbose=0)\n",
    "  param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "  grid = GridSearchCV(estimator = model, param_grid=param_grid, scoring = make_scorer(mean_squared_error, greater_is_better=False),return_train_score = True)\n",
    "  grid_result = grid.fit(features_train_scale, y_train, verbose = 0)\n",
    "  print(grid_result)\n",
    "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "  means = grid_result.cv_results_['mean_test_score']\n",
    "  stds = grid_result.cv_results_['std_test_score']\n",
    "  params = grid_result.cv_results_['params']\n",
    "  for mean, stdev, param in zip(means, stds, params):\n",
    "      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "  print(\"Traininig\")\n",
    "  means = grid_result.cv_results_['mean_train_score']\n",
    "  stds = grid_result.cv_results_['std_train_score']\n",
    "  for mean, stdev, param in zip(means, stds, params):\n",
    "      print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cb24fb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=KerasRegressor(model=<function func at 0x000001E5881D3EE0>, verbose=0),\n",
      "             param_grid={'batch_size': [10, 15, 20], 'epochs': [10, 30, 35]},\n",
      "             return_train_score=True,\n",
      "             scoring=make_scorer(mean_squared_error, greater_is_better=False))\n",
      "Best: -0.003997 using {'batch_size': 20, 'epochs': 30}\n",
      "-0.004479 (0.000725) with: {'batch_size': 10, 'epochs': 10}\n",
      "-0.004100 (0.000533) with: {'batch_size': 10, 'epochs': 30}\n",
      "-0.004582 (0.000936) with: {'batch_size': 10, 'epochs': 35}\n",
      "-0.004835 (0.000567) with: {'batch_size': 15, 'epochs': 10}\n",
      "-0.004882 (0.000708) with: {'batch_size': 15, 'epochs': 30}\n",
      "-0.004781 (0.001239) with: {'batch_size': 15, 'epochs': 35}\n",
      "-0.005296 (0.000757) with: {'batch_size': 20, 'epochs': 10}\n",
      "-0.003997 (0.000271) with: {'batch_size': 20, 'epochs': 30}\n",
      "-0.004744 (0.000832) with: {'batch_size': 20, 'epochs': 35}\n",
      "Traininig\n",
      "-0.002808 (0.000441) with: {'batch_size': 10, 'epochs': 10}\n",
      "-0.002032 (0.000457) with: {'batch_size': 10, 'epochs': 30}\n",
      "-0.001857 (0.000476) with: {'batch_size': 10, 'epochs': 35}\n",
      "-0.003032 (0.000421) with: {'batch_size': 15, 'epochs': 10}\n",
      "-0.001928 (0.000171) with: {'batch_size': 15, 'epochs': 30}\n",
      "-0.001914 (0.000453) with: {'batch_size': 15, 'epochs': 35}\n",
      "-0.002911 (0.000228) with: {'batch_size': 20, 'epochs': 10}\n",
      "-0.002016 (0.000350) with: {'batch_size': 20, 'epochs': 30}\n",
      "-0.001857 (0.000341) with: {'batch_size': 20, 'epochs': 35}\n"
     ]
    }
   ],
   "source": [
    "do_grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "712d4b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e58d00ba30>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=20)\n",
    "my_model.fit(features_train_scale, y_train, epochs = 30, batch_size =20,verbose = 0,callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e946720",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mse, res_mae = my_model.evaluate(features_test_scale,y_test,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e6db9d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07564701611559317 0.05681334808468819\n"
     ]
    }
   ],
   "source": [
    "#The new model has a root-mean-square deviation of .067 and a mean absolute error of .050\n",
    "print(res_mse**.5, res_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e179f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "0.7201725990823444\n"
     ]
    }
   ],
   "source": [
    "predicted_values = my_model.predict(features_test_scale) \n",
    "print(r2_score(y_test, predicted_values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R squared value of .72 means that 72 percent of the variation in the chance of admission is accounted for by my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "52d0b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: My model presents the factors that can help students gain admission to graduate school\n",
    "# By utilizing these findings, students and test prep companies can statigize more efficiently"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
